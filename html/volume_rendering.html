<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>BoltView: Volume Rendering</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">BoltView
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('volume_rendering.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Volume Rendering </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p float="left" align="center"></p>
<p><img src="abdomen.png" alt="Abdomen CT" title="Abdomen CT" width="300" class="inline"/> <img src="bug.png" alt="Bug CT" title="Bug CT" width="300" class="inline"/> </p>
<p>In this example we will show how to implement simple volume renderer based on ray-casting. The goal of this excercise is to show how to employ GPU texture units by storing data in 3D texture image together with complex functor being passed to <code><a class="el" href="group___algorithms.html#gad1858c687309e06c4e4434b2e1743b8d">forEachPosition()</a></code> algorithm.</p>
<p>The first step after data load into the 3D host image is creation of the 3D texture image and transfering the data to the texture.</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">Image&lt;float, 3&gt; input_image(size);</div>
<div class="line">// load ...</div>
<div class="line"> </div>
<div class="line">TextureImage&lt;float, 3&gt; tex_image(input_image.size());</div>
<div class="line">copy(constView(input_image), view(tex_image));</div>
</div><!-- fragment --><p><code>TextureImage&lt;&gt;</code> template have a third template parameter, which specify texture format details - interpolation type, border handling, etc. For now we will use it with default settings, that means trilinear interpolation, border set to zero and data access coordinates are in &lt;0, size) range (not normalized (0,1)).</p>
<p float="left" align="center"></p>
<p><object type="image/svg+xml" data="ray_casting.svg" style="pointer-events: none;" title="Raycasting scheme" width="300">Raycasting scheme</object> </p>
<p>Now that we have the data on the GPU we need to think of parallelization strategy. By simple observation we can deduce that computations of output pixels are independent of each other. So we prepare an image as our render target and execute the ray traversal algorithm. We use <code><a class="el" href="group___algorithms.html#gad1858c687309e06c4e4434b2e1743b8d">forEachPosition()</a></code> algorithm, because have to know where the pixel lies in the output buffer to properly compute the ray direction. For correct ray direction computation we need to specify the <em>camera</em> setup. We have to specify the camera (eye) position and a way to specify its local ortonormal coordinate base. We do it by providing a position of a point in space where the camera looks (we use center of our dataset) and up direction (third basis vector can be computed by cross product), we also need to specify the <em>field of view</em> of our camera.</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">struct Camera {</div>
<div class="line">    Float3 lookat;</div>
<div class="line">    Float3 eye;</div>
<div class="line">    Float3 up;</div>
<div class="line">    float fov = 50.0f;</div>
<div class="line">};</div>
</div><!-- fragment --><p>Actual rendering procedure would than look like this: </p><div class="fragment"><div class="line"> {c++}</div>
<div class="line">UnifiedImage&lt;RGBAf, 2&gt; render(output_size);</div>
<div class="line"> </div>
<div class="line">forEachPosition(</div>
<div class="line">    view(render),</div>
<div class="line">    RayTraversal&lt;TView&gt;(image, render.size(), camera));</div>
</div><!-- fragment --><p>The <code>RayTraversal</code> functor constructor takes a view for our volumetric data, screen size and camera setup. Voxel values in our CT test data represent absorption of the X-ray beam. We can thus simulate classic X-ray imaging just by proper mapping of these densities onto (0.0, 1.0) alpha channel as can be seen in teh following image.</p>
<p float="left" align="center"></p>
<p><img src="abdomen_xray.jpg" alt="Abdomen XRay" title="Abdomen XRay" width="300" class="inline"/> </p>
<p>More interesting images can be rendered by providing some mapping between scalar values and color with alpha channel. This is usually done via so call <em>tranfer functions</em>, which provides such mapping. We can load sample transfer function for our dataset - it just table of value/RGBA pairs. We can store it in simple buffer and pass it also to the <code>RayTraversal</code> functor:</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">forEachPosition(</div>
<div class="line">    view(render),</div>
<div class="line">    RayTraversal&lt;TView, TTransferFunc&gt;(image, tf, render.size(), camera));</div>
</div><!-- fragment --><p><code>RayTraversal</code> functor needs to compute a ray direction and scale it to reflect the sampling rate. It then proceeds and tranverses the ray. For each sample it reads an interpolated value from the rendered volume (texture), maps the value via 1D transfer function into RGBA value and blends it with the intermediate ray color (this approach is called front-to-back rendering).</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">template&lt;typename TView, typename TTransFunction&gt;</div>
<div class="line">struct RayTraversal {</div>
<div class="line">    // constructor ...</div>
<div class="line">    // members ...</div>
<div class="line"> </div>
<div class="line">    BOLT_DECL_DEVICE</div>
<div class="line">    Float3 computeStep(Int2 coords) const {</div>
<div class="line">        Float2 plane_pos = coords - (0.5f * resolution_);</div>
<div class="line">        Float3 pos = plane_center_ + plane_pos[0] * x_step_ + plane_pos[1] * y_step_;</div>
<div class="line">        return normalize(pos - eye_);</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    BOLT_DECL_DEVICE</div>
<div class="line">    void operator()(RGBAf &amp;color, Int2 coords) const {</div>
<div class="line">        Float3 step = step_size_ * computeStep(coords);</div>
<div class="line">        Float3 current_position = eye_ + 800*step;</div>
<div class="line">        RGBAf res;</div>
<div class="line">        for (int i = 0; i &lt; kSampleCount; ++i) {</div>
<div class="line">            auto sample = volume_.access(current_position);</div>
<div class="line">            RGBAf color = tf_[round(sample)];</div>
<div class="line"> </div>
<div class="line">            res = frontToBackBlend(res, color, step_size_);</div>
<div class="line">            current_position += step;</div>
<div class="line">        }</div>
<div class="line">        color = res;</div>
<div class="line">    }</div>
<div class="line">};</div>
</div><!-- fragment --><p>There are lots of possible improvements to this method, which can influence quality and rendering speed like antialiasing, early ray traversal termination, ...</p>
<p>But we will do here just one improvement to get nicer output. We will add a little bit of shading to help emphasize the overal structure of the objects in the volume. We need to compute a normal vector. If we consider an isosurface in 3D data then its noraml direction is aligned with the local gradient. So we will estimate the normal direction by computing finite differences in all 3 dimensions. Since we should already have the central value, we will pass it as an argument to prevent unnecessary texture read.</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">template&lt;typename TView&gt;</div>
<div class="line">BOLT_DECL_DEVICE</div>
<div class="line">Float3 computeGradient(TView volume, float value, Float3 current_position, float epsilon) {</div>
<div class="line">    return {</div>
<div class="line">        (value - volume.access(current_position - Float3(epsilon, 0.0f, 0.0f))) / epsilon,</div>
<div class="line">        (value - volume.access(current_position - Float3(0.0f, epsilon, 0.0f))) / epsilon,</div>
<div class="line">        (value - volume.access(current_position - Float3(0.0f, 0.0f, epsilon))) / epsilon</div>
<div class="line">    };</div>
<div class="line">}</div>
</div><!-- fragment --><p>Updated functor will look like this. Where shading is applied by modulating sample color, based on light position, chosen material properties, view direction and normal direction.</p>
<div class="fragment"><div class="line"> {c++}</div>
<div class="line">BOLT_DECL_DEVICE</div>
<div class="line">void operator()(RGBAf &amp;color, Int2 coords) const {</div>
<div class="line">    Float3 step = step_size_ * computeStep(coords);</div>
<div class="line">    Float3 current_position = eye_ + 800*step;</div>
<div class="line">    RGBAf res;</div>
<div class="line">    for (int i = 0; i &lt; kSampleCount; ++i) {</div>
<div class="line">        auto sample = volume_.access(current_position);</div>
<div class="line">        auto gradient = computeGradient(volume_, sample, current_position, kGradientEpsilon);</div>
<div class="line">        RGBAf color = tf_[round(sample)];</div>
<div class="line">        color = doShading(</div>
<div class="line">            current_position,</div>
<div class="line">            color,</div>
<div class="line">            light_,</div>
<div class="line">            material_,</div>
<div class="line">            eye_,</div>
<div class="line">            gradient);</div>
<div class="line"> </div>
<div class="line">        res = frontToBackBlend(res, color, step_size_);</div>
<div class="line">        current_position += step;</div>
<div class="line">    }</div>
<div class="line">    color = res;</div>
<div class="line">}</div>
</div><!-- fragment --><p>You can see sample outputs from the render at the top of the page. </p><pre class="fragment">* CT scan of human abdomen - you can clearly identify pelvis, kidneys, liver, ...
* CT scan of stag beetle
</pre> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.8.13-->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.17 </li>
  </ul>
</div>
</body>
</html>
